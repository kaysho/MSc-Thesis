{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Computing\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that I have the whole string for the day, I need to do processing first, before spliting them into chunks. \n",
    "words = set(nltk.corpus.words.words())\n",
    "#I need to add in some crypto currency specific words. like Etherum.\n",
    "#bascailly all the symbols of crypto currencies, I should add a set here. \n",
    "cryptowords=(['crypto','cryptocurrency','bitcoin','btc','etherum','eos','eth','xrp','ltc'])\n",
    "words.update(cryptowords)\n",
    "\n",
    "exclusionli=['up','so','if','go'] #keep in view\n",
    "\n",
    "\n",
    "def processTweet(tweetFeed):\n",
    "    tweetFeed = tweetFeed.lower()\n",
    "    #Convert www.* or https?://* pic.twitter.com* to space\n",
    "    tweetFeed = re.sub('(https:\\/\\/www\\.[\\s][\\a-zA-Z]*)|(http:\\/\\/www\\.[\\s][\\a-zA-Z]*)|(https:\\/\\/[\\s][\\a-zA-Z]*)|(http:\\/\\/[\\s][\\a-zA-Z]*)|(www\\.[\\s][\\a-zA-Z]*)|(https:\\/\\/[\\a-zA-Z]*)|(http:\\/\\/[\\a-zA-Z]*)',' ',tweetFeed)\n",
    "    tweetFeed = re.sub('pic\\.[^\\s]*',' ',tweetFeed)\n",
    "    #removw @sth and #sth\n",
    "    tweetFeed = re.sub('(@\\ [^\\s]*)|(#\\ [^\\s]*)', ' ', tweetFeed)\n",
    "    #remove rt\n",
    "    tweetFeed = re.sub('rt[\\s]','',tweetFeed)\n",
    "\n",
    "    tweetFeed = \" \".join(w for w in nltk.wordpunct_tokenize(tweetFeed) if w.lower() in words)# or not w.isalpha())#this part takes in number as True.\n",
    "    #I'm not so sure about this language filter, but let's just roll with it first. \n",
    "    tweetFeed = re.sub(\"[^A-Za-z']+\", ' ', tweetFeed)\n",
    "\n",
    "    #filter out all the token left with len of 1. possibaly 2, defind a exclusion list: up, if, so, \n",
    "    tweetFeed = \" \".join(w for w in nltk.wordpunct_tokenize(tweetFeed) if len(w) >1 )\n",
    "    return tweetFeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's try to split the text into smaller chunks, which is just taking the tutorial's code\n",
    "def get_split(text1,length=200, overlap=50):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//(length-overlap) >0:\n",
    "    n = len(text1.split())//(length-overlap)\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:length]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*(length-overlap):w*(length-overlap) + length]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12052\\2971903560.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[1;31m#df=df['text'].to_frame()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0mrawtxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mrawtxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Computing\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#next, tie them up, read in csv, combine into chunks, take the dates as the price? \n",
    "path = '../archive/data/tweets'\n",
    "all_files = glob.glob(path+'/*.csv')\n",
    "\n",
    "#let me try to use list1 to store string and list 2 to store dates\n",
    "li1=[]\n",
    "li2=[]\n",
    "for file in all_files:\n",
    "  df=pd.read_csv(file,sep=',',index_col=0)\n",
    "  df=df['text'].to_frame()\n",
    "  rawtxt=[]\n",
    "  for row in df.text:\n",
    "    rawtxt.append(row)\n",
    "  string = \" \".join(rawtxt)\n",
    "\n",
    "  date= file[-14:-4]\n",
    "  \n",
    "  li1.append(string)\n",
    "  li2.append(date)\n",
    "\n",
    "data=pd.DataFrame({'date':li2, 'text':li1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "start_date ='2018-12-28'\n",
    "end_date = '2019-04-02'\n",
    "price = yf.download(\"BTC-USD\", start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>3653.131836</td>\n",
       "      <td>3956.135986</td>\n",
       "      <td>3642.632080</td>\n",
       "      <td>3923.918701</td>\n",
       "      <td>3923.918701</td>\n",
       "      <td>5631554348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-29</th>\n",
       "      <td>3932.491699</td>\n",
       "      <td>3963.758789</td>\n",
       "      <td>3820.408691</td>\n",
       "      <td>3820.408691</td>\n",
       "      <td>3820.408691</td>\n",
       "      <td>4991655917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-30</th>\n",
       "      <td>3822.384766</td>\n",
       "      <td>3901.908936</td>\n",
       "      <td>3797.219238</td>\n",
       "      <td>3865.952637</td>\n",
       "      <td>3865.952637</td>\n",
       "      <td>4770578575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>3866.839111</td>\n",
       "      <td>3868.742920</td>\n",
       "      <td>3725.867432</td>\n",
       "      <td>3742.700439</td>\n",
       "      <td>3742.700439</td>\n",
       "      <td>4661840806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>3746.713379</td>\n",
       "      <td>3850.913818</td>\n",
       "      <td>3707.231201</td>\n",
       "      <td>3843.520020</td>\n",
       "      <td>3843.520020</td>\n",
       "      <td>4324200990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2018-12-28  3653.131836  3956.135986  3642.632080  3923.918701  3923.918701   \n",
       "2018-12-29  3932.491699  3963.758789  3820.408691  3820.408691  3820.408691   \n",
       "2018-12-30  3822.384766  3901.908936  3797.219238  3865.952637  3865.952637   \n",
       "2018-12-31  3866.839111  3868.742920  3725.867432  3742.700439  3742.700439   \n",
       "2019-01-01  3746.713379  3850.913818  3707.231201  3843.520020  3843.520020   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2018-12-28  5631554348  \n",
       "2018-12-29  4991655917  \n",
       "2018-12-30  4770578575  \n",
       "2018-12-31  4661840806  \n",
       "2019-01-01  4324200990  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24905e458ad4dc5a4619ab5330e2c95bb62fcc8cfba758a3e378b0342911d66f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
